<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Detector de Audio Independencia</title>
</head>
<body>
    <h1>Detector de Audio Independencia</h1>
    <label for="umbralInput">Umbral de Decibelios:</label>
    <input type="range" id="umbralInput" min="0" max="100" value="10" step="1" oninput="updateUmbral()">
    <span id="umbralValue">1.0</span>
    <div id="eventCounter">Veces que se ha superado el umbral: 0</div>
    <br/>
    <button onclick="startAudioDetection()">Iniciar Detección</button>
    <button onclick="stopAudioDetection()">Detener Detección</button>
    <div id="powerDisplay">Potencia de Audio: 0 dB</div>
    <div id="eventLog"></div>
    <button onclick="saveInformation()">Guardar Información</button>

    <script>
        let audioContext;
        let analyser;
        let microphoneStream;
        let eventLogElement;
        let eventCounterElement;
        let count = 0;
        let lastSpeechTime = 0;
        const speechCooldownDuration = 30000; // Tiempo en milisegundos para ignorar detecciones después de la síntesis de voz
        let umbralDecibelios = 1.0;
        let umbralValue = document.getElementById('umbralValue');

        function updateUmbral() {
            umbralDecibelios = parseFloat((parseInt(document.getElementById('umbralInput').value) / 10).toFixed(1));
            umbralValue.textContent = umbralDecibelios.toFixed(1);
        }

        function startAudioDetection() {
            eventLogElement = document.getElementById('eventLog');
            eventCounterElement = document.getElementById('eventCounter');

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(function (stream) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    microphoneStream = audioContext.createMediaStreamSource(stream);

                    microphoneStream.connect(analyser);
                    analyser.connect(audioContext.destination);

                    analyser.fftSize = 256;
                    analyser.smoothingTimeConstant = 0.5; // Ajusta este valor según sea necesario

                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);

                    analyser.getByteTimeDomainData(dataArray);

                    function detectAudio() {
                        analyser.getByteTimeDomainData(dataArray);

                        // Calcula la potencia del audio en dB
                        const rms = Math.sqrt(Array.from(dataArray).reduce((sum, sample) => sum + Math.abs(sample) * Math.abs(sample), 0) / dataArray.length);
                        const dB = 20 * Math.log10(rms / 128.0); // Se ajusta para normalizar a 0-1

                        // Muestra la potencia del audio en la interfaz
                        document.getElementById('powerDisplay').innerText = `Potencia de Audio: ${dB.toFixed(2)} dB`;

                        // Verifica si la potencia supera el umbral y registra el evento
                        if (dB > umbralDecibelios && !isSpeechCooldownActive()) {
                            const evento = `Evento detectado a las ${getCurrentTime()} con potencia ${dB.toFixed(2)} dB`;
                            logEvent(evento);
                            count++;
                            updateEventCounter();
                            readEventCount();
                        }

                        requestAnimationFrame(detectAudio);
                    }

                    detectAudio();
                })
                .catch(function (err) {
                    console.error("Error al obtener acceso al micrófono:", err);
                });
        }

        function stopAudioDetection() {
            if (microphoneStream) {
                microphoneStream.disconnect();
                analyser.disconnect();
                audioContext.close().then(() => {
                    console.log("Detección de audio detenida.");
                });
            }
        }

        function logEvent(message) {
            const eventItem = document.createElement('div');
            eventItem.innerText = message;

            // Inserta el nuevo evento al principio de la lista
            eventLogElement.insertBefore(eventItem, eventLogElement.firstChild);
        }

        function updateEventCounter() {
            eventCounterElement.innerText = `Veces que se ha superado el umbral: ${count}`;
        }

        function readEventCount() {
            // Pausa temporalmente la detección de audio durante la síntesis de voz
            pauseAudioDetection();

            // Utiliza la API de Web Speech para leer en voz alta el número de eventos detectados con un mensaje personalizado
            const synth = window.speechSynthesis;
            const message = `Dario tu empresa afecta a los Vecinos con Ruido Execivo y Olores Toxicos. Generando Informe: ${count}.`;
            const utterance = new SpeechSynthesisUtterance(message);
            utterance.onend = () => {
                // Después de leer el mensaje, reanuda la detección de audio
                resumeAudioDetection();
                // Lee la fecha y hora de una manera más simple
                readDateTime();
            };
            synth.speak(utterance);

            // Registra el tiempo de la última síntesis de voz
            lastSpeechTime = Date.now();
        }

        function isSpeechCooldownActive() {
            // Verifica si el tiempo transcurrido desde la última síntesis de voz es menor que el período de espera
            return Date.now() - lastSpeechTime < speechCooldownDuration;
        }

        function getCurrentTime() {
            const now = new Date();
            const hours = now.getHours();
            const minutes = now.getMinutes();
            const ampm = hours >= 12 ? 'pm' : 'am';
            const hourText = hours % 12 === 0 ? 12 : hours % 12;
            const minuteText = minutes < 10 ? `0${minutes}` : minutes;
            return `${hourText}:${minuteText} ${ampm}`;
        }

        function pauseAudioDetection() {
            // Pausa la detección de audio desconectando el micrófono
            if (microphoneStream) {
                microphoneStream.disconnect();
            }
        }

        function resumeAudioDetection() {
            // Reanuda la detección de audio reconectando el micrófono
            if (microphoneStream && analyser) {
                microphoneStream.connect(analyser);
            }
        }

        function readDateTime() {
            // Lee la fecha y hora de una manera más simple
            const now = new Date();
            const options = { hour: 'numeric', minute: 'numeric', hour12: true };
            const dateTimeString = now.toLocaleString('en-MX', options);
            const synth = window.speechSynthesis;
            const utterance = new SpeechSynthesisUtterance(`Hora actual: ${dateTimeString}`);
            synth.speak(utterance);
        }

        function saveInformation() {
            const events = Array.from(document.getElementById('eventLog').children).map(event => event.innerText);
            const content = `Registro de eventos:\n${events.join('\n')}`;

            // Crear un Blob con el contenido del archivo
            const blob = new Blob([content], { type: 'text/plain' });

            // Crear un enlace de descarga
            const link = document.createElement('a');
            link.href = URL.createObjectURL(blob);
            link.download = 'registro_eventos.txt';

            // Simular un clic en el enlace para iniciar la descarga
            link.click();
        }
    </script>
</body>
</html>
